{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个guide主要说明怎么样完成下面这几个部分：\n",
    "* 怎样管理自己的TensorFlow程序(__tf.Graph__)和TensorFlow的运行(runtime)(__tf.Session__),而不是通过Estimators去管理他们。\n",
    "* 怎样通过__tf.Session__ 运行TensorFlow的Operations。\n",
    "* 怎么样在low level的环境下使用high level的成分(datasets, layers, feature_columns)。\n",
    "* 怎么样不适用Estimator而创建一个自己的training循环。\n",
    "当可能的情况下，推荐使用高级别的API。知道TensorFlow的核心部分有以下原因：\n",
    "* 当你可以使用一个low level TensorFlow operations的时候实验和调试都会更加直观。\n",
    "* 让你知道在使用高级别的API的时候模型是怎么样内在运行的\n",
    "\n",
    "## Setup\n",
    "在每个程序的开始之前，先运行下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Values\n",
    "TensorFlow的核心数据单元是__tensor__ 。一个tensor可以包含一组任意维度任意形状的原始数据值(primitive value)的数组。tensor's __rank__ 是它的维度，它的__shape__ 是一个元组的整数表明这个数组在不同维度上的长度。下面是tensor值得示例：\n",
    "\n",
    "TensorFlow使用numpy数组来表明tensor值(__values__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. # a rank 0 tensor; a scalar with shape [],\n",
    "[1., 2., 3.] # a rank 1 tensor; a vector with shape [3]\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Core Walkthrough\n",
    "TensorFlow Core programs有下面两个分开的部分组成：\n",
    "1. 创建计算图(a __tf.Graph__)\n",
    "2. 运行计算图(using a __tf.Session__)\n",
    "### Graph\n",
    "__computational graph__ 是一系列的TensorFlow operations被组装到一个graph当中，这个graph包含以下两种类型的队形：\n",
    "* Operations(或者说\"ops\"):是graph中的nodes。Operations描述consume和produce tensors的计算。\n",
    "* Tensors: 是graph的边(edges)。这些代表在graph中流动的值，大部分的TensorFlow函数都会返回__tf.Tensors__ 。\n",
    "\n",
    "> __Important：__ tf.Tensors没有值，他们只是在计算graph中的句柄。(tf.Tensors do not have values, they are just handles to elements in the computation graph.)\n",
    "\n",
    "以下例子创建一个简单的计算图形。最基本的operation是常熟。 下面的Python函数创建了将tensor值作为输入的operations。这个操作的结果没有任何的输入，当运行的时候，这个输出的值会传递到构造器。我们可以创建两个浮点类型的常数a,b如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0) # also tf.float32 implicitly\n",
    "total = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意上面打印出来的tensor并没有输出如你所想的值3.0, 4.0, and 7.0。上面的成熟只会建立一个计算图。这些__tf.Tensor__对象值表示这些会运行的operations。\n",
    "\n",
    "在图当中，每一个operation只会给一个唯一的名字。这个名字和Python当中分配给对象的名字是独立的。 Tensors的名字是创建他们的operation的名字的后面再加一个输出的索引号，如上面\"add:0\"所示。\n",
    "\n",
    "### TensorBoard\n",
    "TensorFlow提供一个叫做TensorBoard的工具包。TensorBoard能力中的一个就是显示计算图形。你可以通过下面简单的几句命令做到这点。\n",
    "\n",
    "首先你需要保存一个计算图形到TensorBoard的总结文件，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWrite('.')\n",
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的代码中会在现在的目录中创建一个有下面名字格式的__event__文件：\n",
    "> events.out.tfevents.{timestamp}.{hostname}\n",
    "\n",
    "现在，在一个新的终端，通过shell命令运行TensorBoard:\n",
    "> tensorboard --logdir .\n",
    "\n",
    "然后在浏览器中打开TensorBoard的[图形页面](http://localhost:6006/#graphs)， 你可以看到一个类似于下面的图形界面：\n",
    "![Titile](getting_started_add.png)\n",
    "\n",
    "更多的关于TensorBoard的图形显示的工具参加[ TensorBoard: Graph Visualization.](https://www.tensorflow.org/programmers_guide/graph_viz?hl=zh-cn)\n",
    "\n",
    "### Session\n",
    "为了评估tensors，实例化一个__tf.Session__对象，非正式的称呼为一个__session__。会话包含了TensorFlow的运行状态，还有TensorFlow operations的运行。 如果__tf.Graph__ 是一个像__.py__ 的文件，一个__tf.Session__ 是像python执行的。\n",
    "\n",
    "下面的代码创建了一个__tf.Session__ 对象，并且唤醒了__run__ 方法来评估上面我们创建的__total__ tensor，示例如下1：\n",
    "\n",
    "当你通过__Session.run__ 请求一个节点的输出。TensorFlow回溯到图形，计算所有对这个被请求输出节点提供输入的节点。所以这个被打印的值是7.0.\n",
    "\n",
    "也可以传递多个tensors到 __tf.Session.run__ 。这个__run__ 方法透明的处理元组或者字典的组合，示例如下2：\n",
    "\n",
    "这个返回值有一个相同得布局结构。\n",
    "\n",
    "当调用__tf.Session.run__ 每个__tf.Tensor__ 只会有一个相同的值。例如，下面的代码中调用__tf.random_uniform__ 来长生一个__tf.Tensor__ 生成一个随机的 3-element矢量(只有值[0,1])，示例如3：\n",
    "\n",
    "这个结果表明每次调用run会有不同的随机值，但是在同一个__run__当中会有相同的值（out1 and out2有相同的输入）\n",
    "\n",
    "有一些TensorFlow函数返回 __tf.Operations__ 而不是__tf.Tensors__. 在Operation上面调用__run__的结果是None。你可以运行一个operation来导致一个副作用，而不是来取回一个值。详细查看下面初始化和训练的ops例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "{'total': 7.0, 'ab': (3.0, 4.0)}\n",
      "[ 0.53463995  0.49421775  0.71698451]\n",
      "[ 0.65756512  0.53536665  0.03139257]\n",
      "(array([ 1.81956518,  1.16343856,  1.00031149], dtype=float32), array([ 2.8195653 ,  2.16343856,  2.00031137], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# 1：\n",
    "sess = tf.Session()\n",
    "print(sess.run(total))\n",
    "\n",
    "# 2:\n",
    "print (sess.run({'ab':(a, b), 'total':total}))\n",
    "\n",
    "# 3:\n",
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "print(sess.run(vec))\n",
    "print(sess.run(vec))\n",
    "print(sess.run((out1, out2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding\n",
    "就目前看来(as it stand)，这个graph并不是特别有意义因为它只能永远产生一个常数值。一个graph可以被参数化接收外部输入，被称为__placeholders__。一个__placeholder__是稍后提供一个值得承诺，类似于函数得参数。\n",
    "\n",
    "下面得开始得三行代码像是定义一个有两个输入参数(x,y)，还有一个操作作用于二者得函数。我们可以通过使用一个__feed_dict__参数到run方法来输入placeholder当中具体得值来评估这个graph。\n",
    "\n",
    "如上说明，__feed_dict__参数是用来重写在graph中得任何tensor。placeholder和tf.Tensors得唯一区别就是如果说placeholder没有输入值得化会抛出一个错误。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "z = x+y\n",
    "print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "print(sess.run(z, feed_dict={x: [1, 3], y: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "placeholder作用于简单得实现，但是Datasets是将数据流入模型当中更受喜爱得方法。\n",
    "\n",
    "从Dataset当中获得一个可以运行的 tf.Tensor, 首先你必须将他转换成一个 __tf.data.Iterator__, 然后调用Iterator的 __get_next__ 方法。\n",
    "\n",
    "最简单的创建一个Iterator的方法是用__make_one_shot_iterator__方法。 示例如下， __next_item__ tensor会在每次调用__run__的时候从__my_data__数组中返回一行。\n",
    "\n",
    "当到达数据流的尾部，Dataset会抛出一个OutOfRangeError异常，一般用try except来捕获异常，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[2 3]\n",
      "[4 5]\n",
      "[6 7]\n"
     ]
    }
   ],
   "source": [
    "my_data = [\n",
    "    [0, 1,],\n",
    "    [2, 3,],\n",
    "    [4, 5,],\n",
    "    [6, 7,],\n",
    "]\n",
    "slices = tf.data.Dataset.from_tensor_slices(my_data)\n",
    "next_item = slices.make_one_shot_iterator().get_next()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(sess.run(next_item))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "一个可以训练的模型必须要调整图的值来用同样的输入获得不同的输出。 Layers是将trainable的参数添加到图中比较喜欢的方式。\n",
    "\n",
    "Layers包中变量(variables)和操作(operations)都可以作用于之上。例如一个densely-connected layer将所有的输入通过一个权重加起来到每一个输出，再通过一个可以选择的激活函数。这些连接的权重和编制都是layer对象管理的。\n",
    "\n",
    "### Creating Layers\n",
    "下面的代码创建了一个Dense layer，输入时批量的输入矢量，每个都输出一个单一值。实行一个layer到输入，调用这个layer就像它时一个函数一样，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "y = linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个layer 探查它的输入来决定它内部参数的个数（size）。因此这里我们必须设定x占位符的形状，这样layer可以创建一个正确大小的权重矩阵。\n",
    "\n",
    "现在我们定义了计算的输出，y。这里还有在运行计算之前需要小新的消息信息。\n",
    "\n",
    "### Initializing Layers\n",
    "包含变量的layers必须要在使用之前初始化。虽然可以分别初始化变量，但是我们可以一次性初始化所有的变量通过下面的命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __important:__ 调用 tf.global_variables_initializer() 只会创建和返回一个句柄到TensorFlow operation。 这个op只有在运行__tf.Session.run__的时候才会初始化所有的变量。\n",
    "\n",
    "如注意所示，global_variables_initializer只会初始化在initializer被创建的时候在图中存在的变量。所以，initializer必须时调价到graph构造中的最后一件事情。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Layers\n",
    "当layer被初始化，可以评估linear——model的输出tensor，如同所有的其他tensor。例如，下面的代码产生一个二维的输出矢量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2563138 ]\n",
      " [ 1.60657215]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(y, {x: [[1, 2, 3],[4, 5, 6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Function shortcuts\n",
    "对每个layer类(类似于tf.layer.Dense)。TensorFlow提供一个快捷功能函数。唯一的区别就时这个函数创建和运行通过一次调用。例如，下面的代码实现上面的功能。\n",
    "\n",
    "虽然说便利，这个方法不允许进入(allow no access to) tf.layers.Layer 对象。这就让自检查和调试变得很困难，layer的重复使用也不可能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.83815849]\n",
      " [ 2.98474169]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.layers.dense(x, units=1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature columns\n",
    "用来使用feature columns的最简单的方式是使用__tf.feature_column.input_layer__ 函数。 这个函数接受__dense column__ 的输入，你必须包装它到_tf.feature_column.indicator_column__ 来展示一个categrical column。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'sales' : [[5], [10], [8], [9]],\n",
    "    'department': ['sports', 'sports', 'gardening', 'gardening']}\n",
    "\n",
    "department_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'department', ['sports', 'gardening'])\n",
    "department_column = tf.feature_column.indicator_column(department_column)\n",
    "\n",
    "columns = [\n",
    "    tf.feature_column.numeric_column('sales'),\n",
    "    department_column\n",
    "]\n",
    "\n",
    "inputs = tf.feature_column.input_layer(features, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行inputs tensor会解释features到batch of vectors。\n",
    "\n",
    "Feature columns可以有内在的状态，例如layers，所以他们经常需要被初始化。categorical columns利用内在查阅表，这些都要求一个分开的初始化的op，__tf.tables_initializer__。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_init = tf.global_variables_initializer()\n",
    "table_init = tf.tables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run((var_init, table_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦内在状态被初始化，你可以运行inputs就像其他任何的tf.Tensor。\n",
    "\n",
    "这些可展示了怎么样包装(packed)输入矢量，用one-hot \"department\"作为前两个索引，“sales\"作为第三个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0.   5.]\n",
      " [  1.   0.  10.]\n",
      " [  0.   1.   8.]\n",
      " [  0.   1.   9.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "上面是TensorFlow的核心。现在手动训练一个小的回归模型。\n",
    "\n",
    "### Define the data\n",
    "首先需要定义一些输入x还有每个输入预期的输出y_true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1],[2],[3],[4]], dtype=tf.float32)\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "然后，建立一个有一个输出的简单线性模型：  \n",
    "在通过运行Session评估预测  \n",
    "现在这个模型还没有被训练，所以者个预测的模型还不是很好。这里是我们获得的，每个人的输出都可能是不一样的：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.72980392]\n",
      " [-3.45960784]\n",
      " [-5.18941164]\n",
      " [-6.91921568]]\n"
     ]
    }
   ],
   "source": [
    "linear_model = tf.layers.Dense(units=1)\n",
    "y_pred = linear_model(x)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss\n",
    "为了优化模型，你首先需要定义loss。在这里用MSE，回归问题的标准loss。\n",
    "\n",
    "虽然你可以手动的通过数学操作来解决这个问题，__tf.losses__模块提供了一系列普通的loss函数。可以通过下面的代码来计算MSE。这个将产生一个loss值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.64362\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.mean_squared_error(labels=y_true,predictions=y_pred)\n",
    "print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "TensorFlow提供了__optimizers__ 实现标准的优化算法。这些被作为__tf.train.Optimizer__ 的子类实现。他们累积的(incrementally)改变每个变量来减小loss。最简单的优化算法是梯度下降法(__gradient descent__）,通过__tf.train.GradientDescentOptimizer__ 实现。它根据变量的loss的微分的大小(magnitude)修改变量值。\n",
    "\n",
    "这些代码创建优化必要的所有的graph成分，并且返回一个training operation。当运行的时候，这个training op会在graph中改变变量(update variables)。按照下面的代码可以运行，示例如下：\n",
    "\n",
    "因为train是一个op而不是一个tensor，所以当运行的时候它不会返回一个值，为了在training的时候升级loss(progression of the loss)，可以在同一时间运行loss tensor，产生一个类似于下面的输出。\n",
    "\n",
    "整体示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.64362\n",
      "6.02039\n",
      "4.20004\n",
      "2.93681\n",
      "2.06014\n",
      "1.45171\n",
      "1.0294\n",
      "0.736235\n",
      "0.532682\n",
      "0.391311\n",
      "0.293086\n",
      "0.224802\n",
      "0.177292\n",
      "0.144199\n",
      "0.12111\n",
      "0.104963\n",
      "0.0936335\n",
      "0.0856481\n",
      "0.0799835\n",
      "0.0759301\n",
      "0.0729953\n",
      "0.0708375\n",
      "0.0692196\n",
      "0.067977\n",
      "0.0669955\n",
      "0.0661959\n",
      "0.0655233\n",
      "0.0649394\n",
      "0.0644178\n",
      "0.0639402\n",
      "0.0634937\n",
      "0.0630696\n",
      "0.0626616\n",
      "0.0622655\n",
      "0.0618783\n",
      "0.061498\n",
      "0.0611232\n",
      "0.0607528\n",
      "0.0603861\n",
      "0.0600227\n",
      "0.0596622\n",
      "0.0593043\n",
      "0.0589489\n",
      "0.0585959\n",
      "0.0582452\n",
      "0.0578967\n",
      "0.0575504\n",
      "0.0572061\n",
      "0.056864\n",
      "0.056524\n",
      "0.056186\n",
      "0.05585\n",
      "0.0555161\n",
      "0.0551842\n",
      "0.0548542\n",
      "0.0545262\n",
      "0.0542002\n",
      "0.0538762\n",
      "0.0535541\n",
      "0.0532338\n",
      "0.0529156\n",
      "0.0525992\n",
      "0.0522847\n",
      "0.0519721\n",
      "0.0516614\n",
      "0.0513525\n",
      "0.0510455\n",
      "0.0507403\n",
      "0.0504369\n",
      "0.0501354\n",
      "0.0498356\n",
      "0.0495376\n",
      "0.0492415\n",
      "0.048947\n",
      "0.0486544\n",
      "0.0483635\n",
      "0.0480744\n",
      "0.0477869\n",
      "0.0475012\n",
      "0.0472172\n",
      "0.0469349\n",
      "0.0466543\n",
      "0.0463754\n",
      "0.0460981\n",
      "0.0458225\n",
      "0.0455485\n",
      "0.0452762\n",
      "0.0450055\n",
      "0.0447364\n",
      "0.0444689\n",
      "0.0442031\n",
      "0.0439388\n",
      "0.0436761\n",
      "0.043415\n",
      "0.0431554\n",
      "0.0428973\n",
      "0.0426409\n",
      "0.0423859\n",
      "0.0421325\n",
      "0.0418806\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "for i in range(100):\n",
    "    _, loss_value = sess.run((train, loss))\n",
    "    print(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.9443\n",
      "14.6464\n",
      "10.2757\n",
      "7.24236\n",
      "5.13688\n",
      "3.67527\n",
      "2.66043\n",
      "1.95559\n",
      "1.46587\n",
      "1.12541\n",
      "0.888519\n",
      "0.723504\n",
      "0.608365\n",
      "0.527836\n",
      "0.471327\n",
      "0.431488\n",
      "0.403221\n",
      "0.382986\n",
      "0.368328\n",
      "0.357544\n",
      "0.349451\n",
      "0.34323\n",
      "0.338311\n",
      "0.334299\n",
      "0.33092\n",
      "0.327984\n",
      "0.325358\n",
      "0.322952\n",
      "0.320701\n",
      "0.318561\n",
      "0.316503\n",
      "0.314503\n",
      "0.312549\n",
      "0.310629\n",
      "0.308736\n",
      "0.306865\n",
      "0.305013\n",
      "0.303178\n",
      "0.301357\n",
      "0.299549\n",
      "0.297754\n",
      "0.295971\n",
      "0.2942\n",
      "0.29244\n",
      "0.29069\n",
      "0.288952\n",
      "0.287224\n",
      "0.285506\n",
      "0.283799\n",
      "0.282102\n",
      "0.280415\n",
      "0.278738\n",
      "0.277072\n",
      "0.275415\n",
      "0.273769\n",
      "0.272132\n",
      "0.270505\n",
      "0.268887\n",
      "0.26728\n",
      "0.265682\n",
      "0.264093\n",
      "0.262514\n",
      "0.260945\n",
      "0.259385\n",
      "0.257834\n",
      "0.256292\n",
      "0.25476\n",
      "0.253237\n",
      "0.251723\n",
      "0.250218\n",
      "0.248722\n",
      "0.247235\n",
      "0.245756\n",
      "0.244287\n",
      "0.242826\n",
      "0.241375\n",
      "0.239932\n",
      "0.238497\n",
      "0.237071\n",
      "0.235654\n",
      "0.234245\n",
      "0.232844\n",
      "0.231452\n",
      "0.230068\n",
      "0.228693\n",
      "0.227325\n",
      "0.225966\n",
      "0.224615\n",
      "0.223272\n",
      "0.221937\n",
      "0.22061\n",
      "0.219291\n",
      "0.21798\n",
      "0.216677\n",
      "0.215382\n",
      "0.214094\n",
      "0.212814\n",
      "0.211541\n",
      "0.210277\n",
      "0.209019\n",
      "[[-0.73600465]\n",
      " [-1.35664451]\n",
      " [-1.97728443]\n",
      " [-2.59792423]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n",
    "\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "\n",
    "y_pred = linear_model(x)\n",
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(100):\n",
    "  _, loss_value = sess.run((train, loss))\n",
    "  print(loss_value)\n",
    "\n",
    "print(sess.run(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps\n",
    "To learn more about building models with TensorFlow consider the following:\n",
    "\n",
    "* [Custom Estimators](https://www.tensorflow.org/get_started/custom_estimators?hl=zh-cn), to learn how to build customized models with TensorFlow. Your knowledge of TensorFlow Core will help you understand and debug your own models.\n",
    "If you want to learn more about the inner workings of TensorFlow consider the following documents, which go into more depth on many of the topics discussed here:\n",
    "\n",
    "* [Graphs and Sessions](https://www.tensorflow.org/programmers_guide/graphs?hl=zh-cn)\n",
    "* [Tensors](https://www.tensorflow.org/programmers_guide/tensors?hl=zh-cn)\n",
    "* [Variables](https://www.tensorflow.org/programmers_guide/variables?hl=zh-cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "213/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
