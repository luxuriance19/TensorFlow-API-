{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow __variable__ 是最好的表示被程序操作的shared，persistent state（represent shared, persistent state manipulated by your program.）  \n",
    "通过计算操作，他们的值可以改变  \n",
    "不同于tf.Tensor对象，tf.Variable存在于session.run的内容之外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Variable\n",
    "最好的创建变量的方式是 __tf.get_variable__ 函数，这个函数要求你specify变量的名字，这个名字也可以被其他的复制（other replicas）进入当前的变量，也可以在checkpointing和导出model的时候命名这个变量的值。 __tf.get_variable__ 也可以用来重新使用之前创建的同名变量，让模型可以更加容易的定义重复利用的layers。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'my_variable:0' shape=(1, 2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'my_init_variable:0' shape=(1, 2, 3) dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "# 创建三维的形状为[1,2,3]的tensor，默认的dtype为tf.float32，\n",
    "# 初始化值可以通过tf.glorot_uniform_initializer来获得随机值    \n",
    "my_variable = tf.get_variable(\"my_variable\",[1,2,3])\n",
    "tf.glorot_uniform_initializer()\n",
    "\n",
    "    \n",
    "# 自定义dtype，并且对tf.get_variable初始化：\n",
    "my_int_variable = tf.get_variable(\"my_init_variable\",[1,2,3],dtype=tf.int32,\n",
    "                                 initializer = tf.zeros_initializer)\n",
    "\n",
    "# 初始化tf.Variable为特定值tf.Tensor，这时，不应该定义变量的shape\n",
    "other_variable = tf.get_variable(\"other_variable\", dtype=tf.int32, \n",
    "  initializer=tf.constant([23, 42]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(my_variable)\n",
    "    print(my_int_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable collections\n",
    "collections： lists of tensor或者时其他对象，例如tf.Variable实例  \n",
    "<p>\n",
    "    默认每个 <b>tf.Variable</b>被放置于两个collections中(get placed in the followinf two collections)：<b> *tf.GraphKeys.GLOBAL_VARIABLE</b>--可以对多个devices共享， <b>*tf.GraphKeys.TRAINABLE_VARIABLES</b>--TensorFlow通过计算梯度的变量\n",
    "</p>\n",
    "\n",
    "当不想要某个variable是trainable的时候，将它加到<b>tf.GraphKeys.LOCAL_VARIABLES</b> collection当中，以下的例子当中表示怎么样将一个变量（named my_local）添加到这个collection当中  \n",
    "同样的，你也可以通过 __trainable=False__ 达到目的  \n",
    "<p>\n",
    "    自定义collections,可以用任意string明明，不需要显示的创建一个collection, 在创建完一个变量之后，通过调用 <b>tf.add_to_collection</b>将这个变量（或者是其他对象）添加到这个collection中, 以下举例中，将my_local 变量添加到 <b>my_collection_name</b> 当中  \n",
    "    获取这个collection当中的所有变量（或者其他对象）可以用 <b>tf.get_collection</b>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'my_local:0' shape=() dtype=float32_ref>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_local = tf.get_variable(\"my_local\",shape=(),\n",
    "                           collections=[tf.GraphKeys.LOCAL_VARIABLES])\n",
    "\n",
    "my_non_trainable = tf.get_variable(\"my_non_trainable\",shape=(),\n",
    "                                   trainable=False)\n",
    "tf.add_to_collection(\"my_collection_name\",my_local)\n",
    "tf.get_collection(\"my_collection_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device placement\n",
    "可以将Variable放在特定的device中，例如，将变量v放在第二个GPU当中（用例如下）  \n",
    "将变量放在正确的device当中在分布设置中特别重要。将变量放在workers instead of parameter servers可能会严重降低training速度，更加严重的是可能会让每个worker自己伪造同一个变量的不相关的副本。  \n",
    "__tf.train.replica_device_setter__ 可以自动的将参数放在parameter servers，用例如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:1\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "\n",
    "cluster_spec = {\n",
    "    \"ps\": [\"ps0:2222\", \"ps1:2222\"],\n",
    "    \"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]}\n",
    "with tf.device(tf.train.replica_device_setter(cluster=cluster_spec)):\n",
    "    v = tf.get_variable(\"v\", shape=[20, 20])  # this variable is placed \n",
    "                                            # in the parameter server\n",
    "                                            # by the replica_device_setter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing variables\n",
    "在使用一个变量之前，它必须首先被初始化。如果说在low-level TensorFlow API进行编程（也就是说，显示的自己创造一个图(graph)和会话(sessions)），就必须要显示的初始化这些变量。大多数的high-level框架(frameworks)例如 __tf.contrib.slim__ , __tf.estimator.Estimator__ 和 __Keras__ 都可以自动的在训练模型之前初始化变量。\n",
    "<p>\n",
    "    显示初始化在某些时候是十分有用的，例如在从checkpoint处重新载入模型不重新运行潜在的开销比较大的initializers和在分布设置当中随机初始化变量的时候允许determinism。    \n",
    "    （Explicit initialization is otherwise useful because it allows you not to rerun potentially expensive initializers when reloading a model from a checkpoint as well as allowing determinism when randomly-initialized variables are shared in a distributed setting）\n",
    "    </p>\n",
    "<p>\n",
    "    在train在是之前，可以通过调用 <b>tf.global_variables_initializer()</b> 一步初始化所有的可以trainable变量。 这个函数返回一个operation在 <b>tf.GraphKeys.GLOVAL_VARIABLES</b> 的collection中为所有的初始化变量负责。通过运行这个operation可以初始化所有的变量，用例如下。 \n",
    "    </p>\n",
    "    <p>\n",
    "    当必须要自己对变量初始化的时候，可以运行变量的初始化operation(variable's initializer operation)，用例如下。\n",
    "    </p>  \n",
    "    通过 __tf.report_uninitialized_variables()__ 可以获得一个operation，通过运行这个operation，可以得到所有的没有被初始化的变量名称。\n",
    "    <p>\n",
    "    默认的 <b> tf.global_variables_initializer </b> 在变量初始化的时候不能够确定变量被初始化的顺序。因此，如果一个变量的初始化依赖于另外一个变量，则可能会报错。    </p>\n",
    "    <p>\n",
    "    所以在任何时候需要使用一个变量，但是并非所有于这个变量有关的变量都被初始化的时候，最好似乎用 <b>variable.initialized_value()</b> 而不是使用 <b>variable</b>,用例如下。  \n",
    "    (Any time you use the value of a variable in a context in which not all variables are initialized (say, if you use a variable's value while initializing another variable), it is best to use variable.initialized_value() instead of variable)\n",
    "    </p>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize all variables in one go\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "## initialize a variable on your own\n",
    "session.run(my_variable.initializer)\n",
    "\n",
    "## get names of uninitialized variables\n",
    "print(session.run(tf.report_uinitialized_variables()))\n",
    "\n",
    "## best way to initialize the variables\n",
    "v = tf.get_variable(\"v\",shape=(),initializer=tf.zeros_initializer())\n",
    "w = tf.get_varibale(\"w\",initializer = v.initialized_value()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Variables\n",
    "在TensorFlow graph当中使用 __tf.Variable__ 值和 __tf.Tensor__ 是一样的，如下示例。  \n",
    "赋值给一个变量，可以通过 __assign, assign_add__ 方法，或者是 __tf.Variable__ 类当中的一些方法，示例如下。  \n",
    "大部分TensorFlow optimizers都有特定的ops可以根据类似梯度下降算法来update变量的值。  \n",
    "由于变量值是可变的，可以通过 __tf.Variable.read_value__ 来获取变量的内容，用例如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_4:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# use the value of tf.Variable\n",
    "v=tf.get_variable(\"v\",shape=(),initializer=tf.zeros_initializer())\n",
    "w = v+1  # w is a tf.Tensor which is computed based on the value of v.\n",
    "           # Any time a variable is used in an expression it gets automatically\n",
    "           # converted to a tf.Tensor representing its value\n",
    "with tf.Session() as sess:\n",
    "    sess.run(v.initialized_value())\n",
    "    print(w)\n",
    "    \n",
    "# assign a value to a variable\n",
    "v = tf.get_variable(\"v\",shape=(),initializer=tf.zeros_initializer())\n",
    "assignment = v.assign_add(1)\n",
    "tf.global_variables_initializer().run()\n",
    "assignment.run()\n",
    "\n",
    "# read values of variable\n",
    "with tf.control.dependencies([assignment]):\n",
    "    w = v.read_value()# w is guaranteed to reflect v's value after the\n",
    "                      # assign_add operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing variables\n",
    "TensorFlow支持两种方式共享变量：\n",
    "<ul>\n",
    "    <li>显示的传递<b> tf.Variable </b>对象</li>\n",
    "    <li>隐式的wrapping <b> tf.Variable</b> 对象通过使用 <b> tf.variable_scope </b>对象</li>\n",
    "    </ul>  \n",
    "    <p>\n",
    "    通过显示的传递变量是非常明显的方法。但是隐式的使用TensorFlow的函数共享变量也是比较便利的，例如 <b>tf.layer, tf.metrics</b> 。\n",
    "    </p>  \n",
    "    \n",
    "    variable scope帮助你通过调用函数隐式的创建和使用变量来控制变量的reuse。他们允许变量通过一个hierarchical and understandable way来命名。用例如下1：\n",
    "    <p>\n",
    "    如果说你想要变量可以被共享，你由两个选择：\n",
    "    <ul>\n",
    "        <li> 创建一个同名的scope，并且将参数 <b>reuse=True</b></li>\n",
    "        <li> 利用 <b>scope.reuse_variables()</b> 来触发reuse</li>\n",
    "        </ul>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1:write a function to create a convolutional/relu layer:'\n",
    "def conv_relu(input,kernel_shape,bias_shape):\n",
    "    #Create variable named \"weights\"\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, \n",
    "                              initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\"\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "                            initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input,weights,strides=[1,1,1,1],padding='SAME')\n",
    "    return tf.nn.relu(conv+biases)\n",
    "\n",
    "input1 = tf.random_normal([1,10,10,32])\n",
    "input2 = tf.random_normal([1,20,20,32])\n",
    "x = conv_relu(input1, kernel_shape=[5,5,32,32],bias_shape=[32])\n",
    "x = conv_relu(input2, kernel_shape=[5,5,32,32],bias_shape=[32])# This fails\n",
    "# 第二句fail的原因，因为weights，biases变量已经存在，程序不知道我们当前是想使用\n",
    "# 原有的变量还是重新建立一个新的变量，所有操作冲突，无法执行。\n",
    "\n",
    "# 但是通过不同的scopes来调用conv_relu,就会明确我们是想要创建新的变量，那么程序就会work\n",
    "# this is working when we call conv_relu in different scope\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\"\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])\n",
    "    \n",
    "# sharing variables, resue variable\n",
    "# 使用reuse=True共享变量\n",
    "with tf.variable_scope(\"model\"):\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(\"model\",reuse=True):\n",
    "    output2 = my_image_filter(input2)\n",
    "    \n",
    "# 使用scope.reuse_variables()共享变量\n",
    "with tf.variable_scope(\"model\") as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "    scope.reuse_variables()\n",
    "    output2 = my_image_filger(input2)\n",
    "    \n",
    "# 使用特定的字符串来明明scope给人感觉比较危险，所以，可以在其他变量的基础上初始化一个变量\n",
    "with tf.variable_scope(\"model\") as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(scope, reuse=True):\n",
    "    output2 = my_image_filger(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
